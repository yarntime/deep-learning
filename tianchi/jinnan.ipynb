{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.model_selection import KFold, RepeatedKFold\n",
    "from scipy import sparse\n",
    "import warnings\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./jinnan_round1_train_20181227.csv\")\n",
    "test_df = pd.read_csv(\"./jinnan_round1_testA_20181227.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TimeToInt(str, previous = 0):\n",
    "    now = 0\n",
    "    try:\n",
    "        time = str.split(\":\")\n",
    "        now = (int(time[0]) * 60 + int(time[1])) * 60\n",
    "        if now < previous:\n",
    "            now += 86400\n",
    "    except:\n",
    "        now = previous\n",
    "    return now\n",
    "\n",
    "def getInt(str):\n",
    "    val = str.split(\":\")\n",
    "    return int(val[0]) * 60 + int(val[1])\n",
    "\n",
    "def TimeToDuration(str):\n",
    "    duration = 0\n",
    "    try:\n",
    "        time = str.split(\"-\")\n",
    "        duration = getInt(time[1]) - getInt(time[0])\n",
    "    except:\n",
    "        duration = 0\n",
    "    if duration < 0:\n",
    "        duration += 24 * 60\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample id</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A6</th>\n",
       "      <th>A8</th>\n",
       "      <th>A10</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>...</th>\n",
       "      <th>timeA24</th>\n",
       "      <th>timeA26</th>\n",
       "      <th>timeB5</th>\n",
       "      <th>timeB7</th>\n",
       "      <th>durationA20</th>\n",
       "      <th>durationA28</th>\n",
       "      <th>durationB4</th>\n",
       "      <th>durationB9</th>\n",
       "      <th>durationB10</th>\n",
       "      <th>durationB11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1528</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>79200</td>\n",
       "      <td>81000</td>\n",
       "      <td>115200</td>\n",
       "      <td>127800</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1698</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>72000</td>\n",
       "      <td>75600</td>\n",
       "      <td>82800</td>\n",
       "      <td>108000</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_639</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>72000</td>\n",
       "      <td>75600</td>\n",
       "      <td>82800</td>\n",
       "      <td>90000</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_483</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>27000</td>\n",
       "      <td>28800</td>\n",
       "      <td>55800</td>\n",
       "      <td>64800</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_617</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>100800</td>\n",
       "      <td>104400</td>\n",
       "      <td>111600</td>\n",
       "      <td>118800</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample id   A1   A2     A3   A4    A6   A8  A10  A12  A13     ...       \\\n",
       "0  sample_1528  300  0.0  405.0  700  38.0  0.0  100  102  0.2     ...        \n",
       "1  sample_1698  300  0.0  405.0  700  29.0  0.0  101  103  0.2     ...        \n",
       "2   sample_639  300  0.0  405.0  700  29.0  0.0  102  103  0.2     ...        \n",
       "3   sample_483  300  0.0  405.0  700  38.0  0.0  100  102  0.2     ...        \n",
       "4   sample_617  300  0.0  405.0  700  29.0  0.0  101  103  0.2     ...        \n",
       "\n",
       "   timeA24  timeA26  timeB5  timeB7  durationA20  durationA28  durationB4  \\\n",
       "0    79200    81000  115200  127800           30           30          60   \n",
       "1    72000    75600   82800  108000           60           60          60   \n",
       "2    72000    75600   82800   90000           30           60          60   \n",
       "3    27000    28800   55800   64800           30           60          60   \n",
       "4   100800   104400  111600  118800           60           60          60   \n",
       "\n",
       "  durationB9  durationB10  durationB11  \n",
       "0         90           90            0  \n",
       "1         90           90           60  \n",
       "2         90           90           60  \n",
       "3         90           90            0  \n",
       "4         90           90           60  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['timeA5'] = train_df['A5'].apply(lambda x: TimeToInt(x))\n",
    "train_df['timeA9'] = train_df.apply(lambda x: TimeToInt(x.A9, x.timeA5), axis = 1)\n",
    "train_df['timeA11'] = train_df.apply(lambda x: TimeToInt(x.A11, x.timeA9), axis = 1)\n",
    "train_df['timeA14'] = train_df.apply(lambda x: TimeToInt(x.A14, x.timeA11), axis = 1)\n",
    "train_df['timeA16'] = train_df.apply(lambda x: TimeToInt(x.A16, x.timeA14), axis = 1)\n",
    "train_df['timeA24'] = train_df.apply(lambda x: TimeToInt(x.A24, x.timeA16), axis = 1)\n",
    "train_df['timeA26'] = train_df.apply(lambda x: TimeToInt(x.A26, x.timeA24), axis = 1)\n",
    "train_df['timeB5'] = train_df.apply(lambda x: TimeToInt(x.B5, x.timeA26), axis = 1)\n",
    "train_df['timeB7'] = train_df.apply(lambda x: TimeToInt(x.B7, x.timeB5), axis = 1)\n",
    "train_df = train_df.drop(['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7'], axis=1)\n",
    "col = ['timeA5','timeA9','timeA11','timeA14','timeA16','timeA24','timeA26','timeB5','timeB7']\n",
    "train_df[col] = train_df[col].fillna(0)\n",
    "\n",
    "train_df['durationA20'] = train_df['A20'].apply(lambda x: TimeToDuration(x))\n",
    "train_df['durationA28'] = train_df['A28'].apply(lambda x: TimeToDuration(x))\n",
    "train_df['durationB4'] = train_df['B4'].apply(lambda x: TimeToDuration(x))\n",
    "train_df['durationB9'] = train_df['B9'].apply(lambda x: TimeToDuration(x))\n",
    "train_df['durationB10'] = train_df['B10'].apply(lambda x: TimeToDuration(x))\n",
    "train_df['durationB11'] = train_df['B11'].apply(lambda x: TimeToDuration(x))\n",
    "train_df = train_df.drop(['A20', 'A28', 'B4', 'B9', 'B10', 'B11'], axis=1)\n",
    "col = ['durationA20','durationA28','durationB4','durationB9','durationB10','durationB11']\n",
    "train_df[col] = train_df[col].fillna(0)\n",
    "\n",
    "col = ['A1','A2','A3','A4','A6','A8','A10','A12','A13','A15','A17','A18','A19','A21','A22','A23','A25','A27','B1','B2','B3','B6','B8','B12','B13','B14']\n",
    "train_df[col] = train_df[col].fillna(0)\n",
    "\n",
    "#train_df.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1)\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample id</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A6</th>\n",
       "      <th>A8</th>\n",
       "      <th>A10</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>...</th>\n",
       "      <th>timeA24</th>\n",
       "      <th>timeA26</th>\n",
       "      <th>timeB5</th>\n",
       "      <th>timeB7</th>\n",
       "      <th>durationA20</th>\n",
       "      <th>durationA28</th>\n",
       "      <th>durationB4</th>\n",
       "      <th>durationB9</th>\n",
       "      <th>durationB10</th>\n",
       "      <th>durationB11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1656</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>43200</td>\n",
       "      <td>46800</td>\n",
       "      <td>54000</td>\n",
       "      <td>61200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1548</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>39</td>\n",
       "      <td>80.0</td>\n",
       "      <td>100</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>75600</td>\n",
       "      <td>77400</td>\n",
       "      <td>114600</td>\n",
       "      <td>122400</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_769</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>43200</td>\n",
       "      <td>46800</td>\n",
       "      <td>54000</td>\n",
       "      <td>61200</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_1881</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102</td>\n",
       "      <td>103.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>100800</td>\n",
       "      <td>104400</td>\n",
       "      <td>111600</td>\n",
       "      <td>118800</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_1807</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>100800</td>\n",
       "      <td>104400</td>\n",
       "      <td>111600</td>\n",
       "      <td>118800</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample id   A1   A2     A3   A4  A6    A8  A10    A12  A13     ...       \\\n",
       "0  sample_1656  300  0.0  405.0  700  29   0.0  101  103.0  0.2     ...        \n",
       "1  sample_1548  300  0.0  405.0  700  39  80.0  100  102.0  0.2     ...        \n",
       "2   sample_769  300  0.0  405.0  700  80   0.0  102  104.0  0.2     ...        \n",
       "3  sample_1881  300  0.0  405.0  700  29   0.0  102  103.0  0.2     ...        \n",
       "4  sample_1807  300  0.0  405.0  700  30   0.0  101  104.0  0.2     ...        \n",
       "\n",
       "   timeA24  timeA26  timeB5  timeB7  durationA20  durationA28  durationB4  \\\n",
       "0    43200    46800   54000   61200           60           60          60   \n",
       "1    75600    77400  114600  122400           30           30          80   \n",
       "2    43200    46800   54000   61200           60           60          60   \n",
       "3   100800   104400  111600  118800           60           60          60   \n",
       "4   100800   104400  111600  118800           60           60          60   \n",
       "\n",
       "   durationB9  durationB10  durationB11  \n",
       "0          90           90           60  \n",
       "1          60           90            0  \n",
       "2         180            0            0  \n",
       "3          90           90           60  \n",
       "4          90           90           60  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['timeA5'] = test_df['A5'].apply(lambda x: TimeToInt(x))\n",
    "test_df['timeA9'] = test_df.apply(lambda x: TimeToInt(x.A9, x.timeA5), axis = 1)\n",
    "test_df['timeA11'] = test_df.apply(lambda x: TimeToInt(x.A11, x.timeA9), axis = 1)\n",
    "test_df['timeA14'] = test_df.apply(lambda x: TimeToInt(x.A14, x.timeA11), axis = 1)\n",
    "test_df['timeA16'] = test_df.apply(lambda x: TimeToInt(x.A16, x.timeA14), axis = 1)\n",
    "test_df['timeA24'] = test_df.apply(lambda x: TimeToInt(x.A24, x.timeA16), axis = 1)\n",
    "test_df['timeA26'] = test_df.apply(lambda x: TimeToInt(x.A26, x.timeA24), axis = 1)\n",
    "test_df['timeB5'] = test_df.apply(lambda x: TimeToInt(x.B5, x.timeA26), axis = 1)\n",
    "test_df['timeB7'] = test_df.apply(lambda x: TimeToInt(x.B7, x.timeB5), axis = 1)\n",
    "test_df = test_df.drop(['A5','A7','A9','A11','A14','A16','A24','A26','B5','B7'], axis=1)\n",
    "col = ['timeA5','timeA9','timeA11','timeA14','timeA16','timeA24','timeA26','timeB5','timeB7']\n",
    "test_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "test_df['durationA20'] = test_df['A20'].apply(lambda x: TimeToDuration(x))\n",
    "test_df['durationA28'] = test_df['A28'].apply(lambda x: TimeToDuration(x))\n",
    "test_df['durationB4'] = test_df['B4'].apply(lambda x: TimeToDuration(x))\n",
    "test_df['durationB9'] = test_df['B9'].apply(lambda x: TimeToDuration(x))\n",
    "test_df['durationB10'] = test_df['B10'].apply(lambda x: TimeToDuration(x))\n",
    "test_df['durationB11'] = test_df['B11'].apply(lambda x: TimeToDuration(x))\n",
    "test_df = test_df.drop(['A20', 'A28', 'B4', 'B9', 'B10', 'B11'], axis=1)\n",
    "col = ['durationA20','durationA28','durationB4','durationB9','durationB10','durationB11']\n",
    "test_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "col = ['A1','A2','A3','A4','A6','A8','A10','A12','A13','A15','A17','A18','A19','A21','A22','A23','A25','A27','B1','B2','B3','B6','B8','B12','B13','B14']\n",
    "test_df[col] = test_df[col].fillna(0)\n",
    "\n",
    "#test_df.drop(['B3', 'B13', 'A13', 'A18', 'A23'], axis=1)\n",
    "\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample id</th>\n",
       "      <th>A1</th>\n",
       "      <th>A2</th>\n",
       "      <th>A3</th>\n",
       "      <th>A4</th>\n",
       "      <th>A6</th>\n",
       "      <th>A8</th>\n",
       "      <th>A10</th>\n",
       "      <th>A12</th>\n",
       "      <th>A13</th>\n",
       "      <th>...</th>\n",
       "      <th>timeA24</th>\n",
       "      <th>timeA26</th>\n",
       "      <th>timeB5</th>\n",
       "      <th>timeB7</th>\n",
       "      <th>durationA20</th>\n",
       "      <th>durationA28</th>\n",
       "      <th>durationB4</th>\n",
       "      <th>durationB9</th>\n",
       "      <th>durationB10</th>\n",
       "      <th>durationB11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sample_1528</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>79200</td>\n",
       "      <td>81000</td>\n",
       "      <td>115200</td>\n",
       "      <td>127800</td>\n",
       "      <td>30</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sample_1698</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>72000</td>\n",
       "      <td>75600</td>\n",
       "      <td>82800</td>\n",
       "      <td>108000</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sample_639</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>72000</td>\n",
       "      <td>75600</td>\n",
       "      <td>82800</td>\n",
       "      <td>90000</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sample_483</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100</td>\n",
       "      <td>102</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>27000</td>\n",
       "      <td>28800</td>\n",
       "      <td>55800</td>\n",
       "      <td>64800</td>\n",
       "      <td>30</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sample_617</td>\n",
       "      <td>300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>405.0</td>\n",
       "      <td>700</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101</td>\n",
       "      <td>103</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>100800</td>\n",
       "      <td>104400</td>\n",
       "      <td>111600</td>\n",
       "      <td>118800</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>90</td>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sample id   A1   A2     A3   A4    A6   A8  A10  A12  A13     ...       \\\n",
       "0  sample_1528  300  0.0  405.0  700  38.0  0.0  100  102  0.2     ...        \n",
       "1  sample_1698  300  0.0  405.0  700  29.0  0.0  101  103  0.2     ...        \n",
       "2   sample_639  300  0.0  405.0  700  29.0  0.0  102  103  0.2     ...        \n",
       "3   sample_483  300  0.0  405.0  700  38.0  0.0  100  102  0.2     ...        \n",
       "4   sample_617  300  0.0  405.0  700  29.0  0.0  101  103  0.2     ...        \n",
       "\n",
       "   timeA24  timeA26  timeB5  timeB7  durationA20  durationA28  durationB4  \\\n",
       "0    79200    81000  115200  127800           30           30          60   \n",
       "1    72000    75600   82800  108000           60           60          60   \n",
       "2    72000    75600   82800   90000           30           60          60   \n",
       "3    27000    28800   55800   64800           30           60          60   \n",
       "4   100800   104400  111600  118800           60           60          60   \n",
       "\n",
       "  durationB9  durationB10  durationB11  \n",
       "0         90           90            0  \n",
       "1         90           90           60  \n",
       "2         90           90           60  \n",
       "3         90           90            0  \n",
       "4         90           90           60  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def toFloat(str):\n",
    "    try:\n",
    "        return float(str)\n",
    "    except:\n",
    "        return float(0)\n",
    "train_set = train_df\n",
    "train_set.loc[train_set['A25'].apply(lambda x: toFloat(x))]\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = train_df['score']\n",
    "del train_df['score']\n",
    "data = pd.concat([train_df,test_df],axis=0,ignore_index=True)\n",
    "data = data.fillna(-1)\n",
    "\n",
    "cate_columns = [f for f in data.columns if f != 'sample id']\n",
    "\n",
    "#label encoder\n",
    "for f in cate_columns:\n",
    "    data[f] = data[f].map(dict(zip(data[f].unique(), range(0, data[f].nunique()))))\n",
    "train = data[:train_df.shape[0]]\n",
    "test  = data[train_df.shape[0]:]\n",
    "\n",
    "# one-hot\n",
    "X_train = pd.DataFrame()\n",
    "X_test = pd.DataFrame()\n",
    "enc = OneHotEncoder(categories='auto')\n",
    "for f in cate_columns:\n",
    "    enc.fit(data[f].values.reshape(-1, 1))\n",
    "    X_train = sparse.hstack((X_train, enc.transform(train[f].values.reshape(-1, 1))), 'csr')\n",
    "    X_test = sparse.hstack((X_test, enc.transform(test[f].values.reshape(-1, 1))), 'csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000425438\tvalid_1's l2: 0.000281007\n",
      "[400]\ttraining's l2: 0.000356215\tvalid_1's l2: 0.000253332\n",
      "[600]\ttraining's l2: 0.000325319\tvalid_1's l2: 0.000245459\n",
      "[800]\ttraining's l2: 0.000305443\tvalid_1's l2: 0.000243671\n",
      "[1000]\ttraining's l2: 0.000289963\tvalid_1's l2: 0.000242866\n",
      "[1200]\ttraining's l2: 0.000278579\tvalid_1's l2: 0.000242488\n",
      "Early stopping, best iteration is:\n",
      "[1103]\ttraining's l2: 0.000283148\tvalid_1's l2: 0.000242101\n",
      "fold n°2\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000361687\tvalid_1's l2: 0.000759779\n",
      "[400]\ttraining's l2: 0.000286976\tvalid_1's l2: 0.000672346\n",
      "[600]\ttraining's l2: 0.000259735\tvalid_1's l2: 0.000640738\n",
      "[800]\ttraining's l2: 0.000244344\tvalid_1's l2: 0.000622099\n",
      "[1000]\ttraining's l2: 0.000234182\tvalid_1's l2: 0.000607684\n",
      "[1200]\ttraining's l2: 0.000227443\tvalid_1's l2: 0.000597992\n",
      "[1400]\ttraining's l2: 0.000222191\tvalid_1's l2: 0.000589849\n",
      "[1600]\ttraining's l2: 0.000218018\tvalid_1's l2: 0.000582912\n",
      "[1800]\ttraining's l2: 0.000214762\tvalid_1's l2: 0.000578408\n",
      "[2000]\ttraining's l2: 0.000211854\tvalid_1's l2: 0.000573919\n",
      "[2200]\ttraining's l2: 0.000209575\tvalid_1's l2: 0.000570297\n",
      "[2400]\ttraining's l2: 0.00020735\tvalid_1's l2: 0.000567088\n",
      "[2600]\ttraining's l2: 0.000205033\tvalid_1's l2: 0.000563396\n",
      "[2800]\ttraining's l2: 0.000203106\tvalid_1's l2: 0.000560552\n",
      "[3000]\ttraining's l2: 0.000201581\tvalid_1's l2: 0.000557932\n",
      "[3200]\ttraining's l2: 0.000200189\tvalid_1's l2: 0.000555747\n",
      "[3400]\ttraining's l2: 0.00019876\tvalid_1's l2: 0.000553765\n",
      "[3600]\ttraining's l2: 0.000197498\tvalid_1's l2: 0.000551725\n",
      "Early stopping, best iteration is:\n",
      "[3649]\ttraining's l2: 0.000197069\tvalid_1's l2: 0.000551174\n",
      "fold n°3\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000432425\tvalid_1's l2: 0.000315499\n",
      "[400]\ttraining's l2: 0.000359809\tvalid_1's l2: 0.000251966\n",
      "[600]\ttraining's l2: 0.000328187\tvalid_1's l2: 0.000232154\n",
      "[800]\ttraining's l2: 0.000309009\tvalid_1's l2: 0.000225197\n",
      "[1000]\ttraining's l2: 0.000296872\tvalid_1's l2: 0.000222057\n",
      "[1200]\ttraining's l2: 0.000286684\tvalid_1's l2: 0.000219863\n",
      "[1400]\ttraining's l2: 0.000278915\tvalid_1's l2: 0.000218032\n",
      "[1600]\ttraining's l2: 0.000271942\tvalid_1's l2: 0.000216738\n",
      "[1800]\ttraining's l2: 0.000266138\tvalid_1's l2: 0.000214959\n",
      "[2000]\ttraining's l2: 0.000260186\tvalid_1's l2: 0.000212556\n",
      "[2200]\ttraining's l2: 0.000255555\tvalid_1's l2: 0.000211769\n",
      "[2400]\ttraining's l2: 0.000251445\tvalid_1's l2: 0.00021034\n",
      "[2600]\ttraining's l2: 0.000248004\tvalid_1's l2: 0.000209585\n",
      "[2800]\ttraining's l2: 0.000244462\tvalid_1's l2: 0.00020812\n",
      "[3000]\ttraining's l2: 0.000241308\tvalid_1's l2: 0.000207207\n",
      "[3200]\ttraining's l2: 0.000238211\tvalid_1's l2: 0.00020655\n",
      "Early stopping, best iteration is:\n",
      "[3201]\ttraining's l2: 0.000238192\tvalid_1's l2: 0.000206539\n",
      "fold n°4\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000355725\tvalid_1's l2: 0.000461503\n",
      "[400]\ttraining's l2: 0.000289496\tvalid_1's l2: 0.000404422\n",
      "[600]\ttraining's l2: 0.000264547\tvalid_1's l2: 0.00038673\n",
      "[800]\ttraining's l2: 0.000249351\tvalid_1's l2: 0.00037809\n",
      "[1000]\ttraining's l2: 0.000238611\tvalid_1's l2: 0.000372425\n",
      "[1200]\ttraining's l2: 0.000230505\tvalid_1's l2: 0.000368287\n",
      "[1400]\ttraining's l2: 0.000224528\tvalid_1's l2: 0.000365449\n",
      "[1600]\ttraining's l2: 0.000219758\tvalid_1's l2: 0.000363448\n",
      "[1800]\ttraining's l2: 0.00021549\tvalid_1's l2: 0.000362544\n",
      "[2000]\ttraining's l2: 0.000211599\tvalid_1's l2: 0.000360475\n",
      "[2200]\ttraining's l2: 0.000208347\tvalid_1's l2: 0.000359132\n",
      "[2400]\ttraining's l2: 0.000205549\tvalid_1's l2: 0.000358257\n",
      "Early stopping, best iteration is:\n",
      "[2401]\ttraining's l2: 0.000205544\tvalid_1's l2: 0.000358248\n",
      "fold n°5\n",
      "Training until validation scores don't improve for 100 rounds.\n",
      "[200]\ttraining's l2: 0.000437459\tvalid_1's l2: 0.000424815\n",
      "[400]\ttraining's l2: 0.000361877\tvalid_1's l2: 0.000350525\n",
      "[600]\ttraining's l2: 0.000327416\tvalid_1's l2: 0.000324739\n",
      "[800]\ttraining's l2: 0.000307489\tvalid_1's l2: 0.000311904\n",
      "[1000]\ttraining's l2: 0.000291488\tvalid_1's l2: 0.000300388\n",
      "[1200]\ttraining's l2: 0.000279671\tvalid_1's l2: 0.000291937\n",
      "[1400]\ttraining's l2: 0.00027082\tvalid_1's l2: 0.000286375\n",
      "[1600]\ttraining's l2: 0.000263612\tvalid_1's l2: 0.000281886\n",
      "[1800]\ttraining's l2: 0.000257419\tvalid_1's l2: 0.000278727\n",
      "[2000]\ttraining's l2: 0.000252594\tvalid_1's l2: 0.000276591\n",
      "[2200]\ttraining's l2: 0.000248248\tvalid_1's l2: 0.000274478\n",
      "[2400]\ttraining's l2: 0.000244072\tvalid_1's l2: 0.000272701\n",
      "[2600]\ttraining's l2: 0.000240534\tvalid_1's l2: 0.000271386\n",
      "[2800]\ttraining's l2: 0.000237437\tvalid_1's l2: 0.000269861\n",
      "[3000]\ttraining's l2: 0.000234653\tvalid_1's l2: 0.000268309\n",
      "[3200]\ttraining's l2: 0.000232088\tvalid_1's l2: 0.000267312\n",
      "[3400]\ttraining's l2: 0.000229704\tvalid_1's l2: 0.000266261\n",
      "[3600]\ttraining's l2: 0.000227447\tvalid_1's l2: 0.000265252\n",
      "[3800]\ttraining's l2: 0.000225307\tvalid_1's l2: 0.000264366\n",
      "[4000]\ttraining's l2: 0.000223296\tvalid_1's l2: 0.000263064\n",
      "[4200]\ttraining's l2: 0.000221567\tvalid_1's l2: 0.000262285\n",
      "[4400]\ttraining's l2: 0.000219747\tvalid_1's l2: 0.000261239\n",
      "[4600]\ttraining's l2: 0.000218198\tvalid_1's l2: 0.000260747\n",
      "[4800]\ttraining's l2: 0.000216565\tvalid_1's l2: 0.000259982\n",
      "[5000]\ttraining's l2: 0.000214878\tvalid_1's l2: 0.000259208\n",
      "[5200]\ttraining's l2: 0.000213374\tvalid_1's l2: 0.00025816\n",
      "[5400]\ttraining's l2: 0.000211974\tvalid_1's l2: 0.000257689\n",
      "[5600]\ttraining's l2: 0.000210773\tvalid_1's l2: 0.000257119\n",
      "[5800]\ttraining's l2: 0.000209469\tvalid_1's l2: 0.000256471\n",
      "[6000]\ttraining's l2: 0.000208249\tvalid_1's l2: 0.000256041\n",
      "Early stopping, best iteration is:\n",
      "[6080]\ttraining's l2: 0.00020775\tvalid_1's l2: 0.000255715\n",
      "CV score: 0.00032 \n"
     ]
    }
   ],
   "source": [
    "y_train = target.values\n",
    "\n",
    "param = {'num_leaves': 120,\n",
    "         'min_data_in_leaf': 30, \n",
    "         'objective':'regression',\n",
    "         'max_depth': -1,\n",
    "         'learning_rate': 0.01,\n",
    "         \"min_child_samples\": 30,\n",
    "         \"boosting\": \"gbdt\",\n",
    "         \"feature_fraction\": 0.9,\n",
    "         \"bagging_freq\": 1,\n",
    "         \"bagging_fraction\": 0.9 ,\n",
    "         \"bagging_seed\": 11,\n",
    "         \"metric\": 'mse',\n",
    "         \"lambda_l1\": 0.1,\n",
    "         \"verbosity\": -1}\n",
    "\n",
    "# 五折交叉验证\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_lgb = np.zeros(len(train))\n",
    "predictions_lgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = lgb.Dataset(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = lgb.Dataset(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    num_round = 10000\n",
    "    clf = lgb.train(param, \n",
    "                    trn_data, \n",
    "                    num_round, \n",
    "                    valid_sets = [trn_data, val_data], \n",
    "                    verbose_eval = 200, \n",
    "                    early_stopping_rounds = 100)\n",
    "    oof_lgb[val_idx] = clf.predict(X_train[val_idx], num_iteration=clf.best_iteration)\n",
    "    \n",
    "    predictions_lgb += clf.predict(X_test, num_iteration=clf.best_iteration) / folds.n_splits\n",
    "\n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof, target)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold n°1\n",
      "[0]\ttrain-rmse:0.421991\tvalid_data-rmse:0.423333\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.25671\tvalid_data-rmse:0.25765\n",
      "[200]\ttrain-rmse:0.156682\tvalid_data-rmse:0.15735\n",
      "[300]\ttrain-rmse:0.096126\tvalid_data-rmse:0.096864\n",
      "[400]\ttrain-rmse:0.05961\tvalid_data-rmse:0.060545\n",
      "[500]\ttrain-rmse:0.037799\tvalid_data-rmse:0.039227\n",
      "[600]\ttrain-rmse:0.024895\tvalid_data-rmse:0.02727\n",
      "[700]\ttrain-rmse:0.017371\tvalid_data-rmse:0.020924\n",
      "[800]\ttrain-rmse:0.01303\tvalid_data-rmse:0.017831\n",
      "[900]\ttrain-rmse:0.010532\tvalid_data-rmse:0.016435\n",
      "[1000]\ttrain-rmse:0.009107\tvalid_data-rmse:0.015856\n",
      "[1100]\ttrain-rmse:0.008267\tvalid_data-rmse:0.015632\n",
      "[1200]\ttrain-rmse:0.007725\tvalid_data-rmse:0.015535\n",
      "[1300]\ttrain-rmse:0.007365\tvalid_data-rmse:0.015519\n",
      "[1400]\ttrain-rmse:0.007121\tvalid_data-rmse:0.015534\n",
      "Stopping. Best iteration:\n",
      "[1264]\ttrain-rmse:0.007484\tvalid_data-rmse:0.015511\n",
      "\n",
      "fold n°2\n",
      "[0]\ttrain-rmse:0.422545\tvalid_data-rmse:0.421107\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256928\tvalid_data-rmse:0.255834\n",
      "[200]\ttrain-rmse:0.156727\tvalid_data-rmse:0.156283\n",
      "[300]\ttrain-rmse:0.09608\tvalid_data-rmse:0.096492\n",
      "[400]\ttrain-rmse:0.059508\tvalid_data-rmse:0.061116\n",
      "[500]\ttrain-rmse:0.037682\tvalid_data-rmse:0.040926\n",
      "[600]\ttrain-rmse:0.024741\tvalid_data-rmse:0.030216\n",
      "[700]\ttrain-rmse:0.017154\tvalid_data-rmse:0.025117\n",
      "[800]\ttrain-rmse:0.012764\tvalid_data-rmse:0.022994\n",
      "[900]\ttrain-rmse:0.010226\tvalid_data-rmse:0.022195\n",
      "[1000]\ttrain-rmse:0.008749\tvalid_data-rmse:0.021919\n",
      "[1100]\ttrain-rmse:0.007868\tvalid_data-rmse:0.021857\n",
      "[1200]\ttrain-rmse:0.00733\tvalid_data-rmse:0.021865\n",
      "Stopping. Best iteration:\n",
      "[1096]\ttrain-rmse:0.007897\tvalid_data-rmse:0.021852\n",
      "\n",
      "fold n°3\n",
      "[0]\ttrain-rmse:0.421913\tvalid_data-rmse:0.423643\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256644\tvalid_data-rmse:0.258457\n",
      "[200]\ttrain-rmse:0.156639\tvalid_data-rmse:0.158335\n",
      "[300]\ttrain-rmse:0.096112\tvalid_data-rmse:0.097608\n",
      "[400]\ttrain-rmse:0.059646\tvalid_data-rmse:0.060931\n",
      "[500]\ttrain-rmse:0.037862\tvalid_data-rmse:0.039096\n",
      "[600]\ttrain-rmse:0.024926\tvalid_data-rmse:0.026508\n",
      "[700]\ttrain-rmse:0.017274\tvalid_data-rmse:0.019748\n",
      "[800]\ttrain-rmse:0.012847\tvalid_data-rmse:0.016433\n",
      "[900]\ttrain-rmse:0.010263\tvalid_data-rmse:0.014974\n",
      "[1000]\ttrain-rmse:0.008768\tvalid_data-rmse:0.014327\n",
      "[1100]\ttrain-rmse:0.007863\tvalid_data-rmse:0.014088\n",
      "[1200]\ttrain-rmse:0.007303\tvalid_data-rmse:0.013998\n",
      "[1300]\ttrain-rmse:0.006931\tvalid_data-rmse:0.013989\n",
      "[1400]\ttrain-rmse:0.006669\tvalid_data-rmse:0.014016\n",
      "Stopping. Best iteration:\n",
      "[1264]\ttrain-rmse:0.007046\tvalid_data-rmse:0.013983\n",
      "\n",
      "fold n°4\n",
      "[0]\ttrain-rmse:0.422641\tvalid_data-rmse:0.420727\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.257142\tvalid_data-rmse:0.255375\n",
      "[200]\ttrain-rmse:0.156943\tvalid_data-rmse:0.155566\n",
      "[300]\ttrain-rmse:0.096323\tvalid_data-rmse:0.095615\n",
      "[400]\ttrain-rmse:0.059761\tvalid_data-rmse:0.059987\n",
      "[500]\ttrain-rmse:0.037889\tvalid_data-rmse:0.039434\n",
      "[600]\ttrain-rmse:0.024921\tvalid_data-rmse:0.028255\n",
      "[700]\ttrain-rmse:0.017308\tvalid_data-rmse:0.022791\n",
      "[800]\ttrain-rmse:0.012887\tvalid_data-rmse:0.020457\n",
      "[900]\ttrain-rmse:0.010358\tvalid_data-rmse:0.019598\n",
      "[1000]\ttrain-rmse:0.00889\tvalid_data-rmse:0.019329\n",
      "[1100]\ttrain-rmse:0.008032\tvalid_data-rmse:0.019256\n",
      "[1200]\ttrain-rmse:0.007476\tvalid_data-rmse:0.019263\n",
      "[1300]\ttrain-rmse:0.00712\tvalid_data-rmse:0.019295\n",
      "Stopping. Best iteration:\n",
      "[1127]\ttrain-rmse:0.007856\tvalid_data-rmse:0.019252\n",
      "\n",
      "fold n°5\n",
      "[0]\ttrain-rmse:0.422201\tvalid_data-rmse:0.422475\n",
      "Multiple eval metrics have been passed: 'valid_data-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until valid_data-rmse hasn't improved in 200 rounds.\n",
      "[100]\ttrain-rmse:0.256793\tvalid_data-rmse:0.25727\n",
      "[200]\ttrain-rmse:0.156704\tvalid_data-rmse:0.157424\n",
      "[300]\ttrain-rmse:0.096175\tvalid_data-rmse:0.096969\n",
      "[400]\ttrain-rmse:0.059712\tvalid_data-rmse:0.060637\n",
      "[500]\ttrain-rmse:0.03788\tvalid_data-rmse:0.039143\n",
      "[600]\ttrain-rmse:0.024945\tvalid_data-rmse:0.026918\n",
      "[700]\ttrain-rmse:0.01732\tvalid_data-rmse:0.020361\n",
      "[800]\ttrain-rmse:0.012875\tvalid_data-rmse:0.017125\n",
      "[900]\ttrain-rmse:0.010302\tvalid_data-rmse:0.015675\n",
      "[1000]\ttrain-rmse:0.008824\tvalid_data-rmse:0.015069\n",
      "[1100]\ttrain-rmse:0.007932\tvalid_data-rmse:0.014833\n",
      "[1200]\ttrain-rmse:0.007364\tvalid_data-rmse:0.014772\n",
      "[1300]\ttrain-rmse:0.006987\tvalid_data-rmse:0.014769\n",
      "[1400]\ttrain-rmse:0.006721\tvalid_data-rmse:0.014803\n",
      "Stopping. Best iteration:\n",
      "[1248]\ttrain-rmse:0.007171\tvalid_data-rmse:0.014762\n",
      "\n",
      "CV score: 0.00030040\n"
     ]
    }
   ],
   "source": [
    "##### xgb\n",
    "xgb_params = {'eta': 0.005, 'max_depth': 20, 'subsample': 0.8, 'colsample_bytree': 0.8, \n",
    "          'objective': 'reg:linear', 'eval_metric': 'rmse', 'silent': True, 'nthread': 4}\n",
    "\n",
    "folds = KFold(n_splits=5, shuffle=True, random_state=2018)\n",
    "oof_xgb = np.zeros(len(train))\n",
    "predictions_xgb = np.zeros(len(test))\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    print(\"fold n°{}\".format(fold_+1))\n",
    "    trn_data = xgb.DMatrix(X_train[trn_idx], y_train[trn_idx])\n",
    "    val_data = xgb.DMatrix(X_train[val_idx], y_train[val_idx])\n",
    "\n",
    "    watchlist = [(trn_data, 'train'), (val_data, 'valid_data')]\n",
    "    clf = xgb.train(dtrain=trn_data, num_boost_round=20000, evals=watchlist, early_stopping_rounds=200, verbose_eval=100, params=xgb_params)\n",
    "    oof_xgb[val_idx] = clf.predict(xgb.DMatrix(X_train[val_idx]), ntree_limit=clf.best_ntree_limit)\n",
    "    predictions_xgb += clf.predict(xgb.DMatrix(X_test), ntree_limit=clf.best_ntree_limit) / folds.n_splits\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(oof_xgb, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold 0\n",
      "fold 1\n",
      "fold 2\n",
      "fold 3\n",
      "fold 4\n",
      "fold 5\n",
      "fold 6\n",
      "fold 7\n",
      "fold 8\n",
      "fold 9\n",
      "CV score: 0.00029 \n"
     ]
    }
   ],
   "source": [
    "# 将lgb和xgb的结果进行stacking\n",
    "train_stack = np.vstack([oof_lgb,oof_xgb]).transpose()\n",
    "test_stack = np.vstack([predictions_lgb, predictions_xgb]).transpose()\n",
    "\n",
    "folds_stack = RepeatedKFold(n_splits=5, n_repeats=2, random_state=4590)\n",
    "oof_stack = np.zeros(train_stack.shape[0])\n",
    "predictions = np.zeros(test_stack.shape[0])\n",
    "\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds_stack.split(train_stack,target)):\n",
    "    print(\"fold {}\".format(fold_))\n",
    "    trn_data, trn_y = train_stack[trn_idx], target.iloc[trn_idx].values\n",
    "    val_data, val_y = train_stack[val_idx], target.iloc[val_idx].values\n",
    "    \n",
    "    clf_3 = BayesianRidge()\n",
    "    clf_3.fit(trn_data, trn_y)\n",
    "    \n",
    "    oof_stack[val_idx] = clf_3.predict(val_data)\n",
    "    predictions += clf_3.predict(test_stack) / 10\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(mean_squared_error(target.values, oof_stack)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df = pd.read_csv('submission.csv', header=None)\n",
    "sub_df[1] = predictions\n",
    "sub_df[1] = sub_df[1].apply(lambda x:round(x, 3))\n",
    "sub_df.to_csv(\"submission.csv\", index=False, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
